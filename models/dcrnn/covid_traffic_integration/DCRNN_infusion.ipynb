{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlalchemy as sal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sal\n",
    "\n",
    "endpoint = \"capstone.clihskgj8i7s.us-west-2.rds.amazonaws.com\"\n",
    "user=\"group3\"\n",
    "db=\"db1\"\n",
    "\n",
    "# endpoint = \"capstone.clihskgj8i7s.us-west-2.rds.amazonaws.com\"\n",
    "# user=\"group3\"\n",
    "# db=\"db1\"\n",
    "pw=\"3qLXGOaxMSoqYfj3yAOY\"\n",
    "\n",
    "engine = sal.create_engine('postgresql://%s:%s@%s/%s' % (user, pw, endpoint, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "merged_df = pd.read_pickle('traffic_covid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = '''select record_date,new_cases from traffic_covid_both'''\n",
    "cases = engine.execute(cases).fetchall()\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "fromtime = datetime.datetime.strptime('01-01-2020','%m-%d-%Y')\n",
    "cases = pd.DataFrame(cases)\n",
    "cases[0] = pd.to_datetime(cases[0])\n",
    "cases.set_index(0,inplace = True)\n",
    "cases.fillna(0,inplace = True)\n",
    "cases = cases[cases.index <= '2020-06-29']\n",
    "covid = cases.fillna(0.).to_numpy().astype('float32') # This step was just for COVID encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def convert_to_date(ind):\n",
    "    return datetime.strptime(str(merged_df.index[ind].date()), '%Y-%m-%d')\n",
    "\n",
    "def return_case_index(ind):\n",
    "    #print(convert_to_date(ind))\n",
    "    return cases.index.get_loc(convert_to_date(ind))\n",
    "\n",
    "def relu(arr):\n",
    "    arr[arr < 0] = 0.\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_df.drop('covid_cases',axis = 1)\n",
    "\n",
    "# Fill in missing values\n",
    "\n",
    "horizon = 12\n",
    "rolling_data = df.rolling(horizon,min_periods=1).mean()\n",
    "rolling_data.fillna(rolling_data.mean(),inplace = True)\n",
    "df = df.fillna(rolling_data[df.isnull()])\n",
    "\n",
    "num_samples, num_nodes = (merged_df.shape[0],merged_df.shape[1] - 1)\n",
    "\n",
    "add_time_in_day = True\n",
    "add_day_in_week = False\n",
    "\n",
    "num_samples, num_nodes = df.shape\n",
    "data = np.expand_dims(df.values, axis=-1)\n",
    "data_list = [data]\n",
    "\n",
    "if add_time_in_day:\n",
    "    time_ind = (df.index.values - df.index.values.astype(\"datetime64[D]\")) / np.timedelta64(1, \"D\")\n",
    "    time_in_day = np.tile(time_ind, [1, num_nodes, 1]).transpose((2, 1, 0))\n",
    "    data_list.append(time_in_day)\n",
    "if add_day_in_week:\n",
    "    day_in_week = np.zeros(shape=(num_samples, num_nodes, 7))\n",
    "    day_in_week[np.arange(num_samples), :, df.index.dayofweek] = 1\n",
    "    data_list.append(day_in_week)\n",
    "\n",
    "data = np.concatenate(data_list, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52114, 320, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_offsets = np.sort(np.concatenate((np.arange(-11, 1, 1),)))\n",
    "y_offsets = np.sort(np.arange(1, 13, 1))\n",
    "\n",
    "min_t = abs(min(x_offsets))\n",
    "max_t = abs(num_samples - abs(max(y_offsets)))\n",
    "\n",
    "cov_horizon = 7\n",
    "x = []\n",
    "y = []\n",
    "cov_x = []\n",
    "cov_y = []\n",
    "\n",
    "for t in range(min_t, max_t):\n",
    "    x_t = data[t + x_offsets, ...]\n",
    "    y_t = data[t + y_offsets, ...]\n",
    "    cind = return_case_index(t)\n",
    "    cov_x.append(cases.values[relu(np.arange(cind-cov_horizon,cind))])\n",
    "    cov_y.append(cases.values[cind])\n",
    "    x.append(x_t)\n",
    "    y.append(y_t)\n",
    "    \n",
    "x = np.stack(x, axis=0)\n",
    "y = np.stack(y, axis=0)\n",
    "\n",
    "covid_cases = np.stack(cov_x,axis = 0).astype('float32')\n",
    "#covid_labels = np.stack(cov_y,axis = 0).astype('float32')\n",
    "\n",
    "b = np.transpose(np.tile(covid_cases,(2,1,1,num_nodes)),(2,1,3,0))\n",
    "a = np.transpose(x,(1,0,2,3))\n",
    "\n",
    "x = np.transpose(np.vstack([a,b]),(1,0,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train x:  (36464, 19, 320, 2) y: (36464, 12, 320, 2)\n",
      "val x:  (5209, 19, 320, 2) y: (5209, 12, 320, 2)\n",
      "test x:  (10418, 19, 320, 2) y: (10418, 12, 320, 2)\n"
     ]
    }
   ],
   "source": [
    "num_samples = x.shape[0]\n",
    "num_test = round(num_samples * 0.2)\n",
    "num_train = round(num_samples * 0.7)\n",
    "num_val = num_samples - num_test - num_train\n",
    "\n",
    "x_train, y_train = x[:num_train], y[:num_train]\n",
    "\n",
    "# val\n",
    "x_val, y_val = (\n",
    "    x[num_train: num_train + num_val],\n",
    "    y[num_train: num_train + num_val],\n",
    ")\n",
    "\n",
    "# test\n",
    "x_test, y_test = x[-num_test:], y[-num_test:]\n",
    "\n",
    "for cat in [\"train\", \"val\", \"test\"]:\n",
    "    _x, _y = locals()[\"x_\" + cat], locals()[\"y_\" + cat]\n",
    "    print(cat, \"x: \", _x.shape, \"y:\", _y.shape)\n",
    "    np.savez_compressed(\n",
    "        os.path.join('data_test', \"%s.npz\" % cat),\n",
    "        x=_x,\n",
    "        y=_y,\n",
    "        x_offsets=x_offsets.reshape(list(x_offsets.shape) + [1]),\n",
    "        y_offsets=y_offsets.reshape(list(y_offsets.shape) + [1]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchts.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.load_dataset('data_test',64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covidencoder",
   "language": "python",
   "name": "covidencoder"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

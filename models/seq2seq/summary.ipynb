{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "import os\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from scipy.signal import tukey\n",
    "from torch.utils import data\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "#import torch.utils.data\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Performing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_params(directory):\n",
    "    pts = os.listdir(directory)\n",
    "    min_loss = 1000\n",
    "    best_params = 0 \n",
    "    for i in range(len(pts)):\n",
    "        try:\n",
    "            item = torch.load(directory + \"/\" + pts[i])\n",
    "            loss = item[\"min_valid_loss\"]\n",
    "            if loss <= min_loss:\n",
    "                min_loss = loss\n",
    "                best_params = item\n",
    "        except:\n",
    "            continue\n",
    "    return min_loss, best_params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [folder for folder in os.listdir(os.getcwd()) if 'ipynb' not in folder]\n",
    "min_loss = {}\n",
    "best_params = {}\n",
    "for fold in folders:\n",
    "    min_loss[fold], best_params[fold] = find_best_params(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = ['learning_rate', 'dropout_rate', 'num_layers', 'hidden_dim']\n",
    "print([(param, best_params['lstms_at'][param]) for param in param_names])\n",
    "print(('min_valid_loss', min_loss['lstms_at']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = ['learning_rate', 'dropout_rate', 'num_layers', 'hidden_dim']\n",
    "print([(param, best_params['lstms_attention_at'][param]) for param in param_names])\n",
    "print(('min_valid_loss', min_loss['lstms_attention_at']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = ['learning_rate', 'dropout_rate', 'encode_num_layers', 'decode_num_layers', 'hidden_dim', 'kernel_size']\n",
    "print([(param, best_params['tcn_at'][param]) for param in param_names])\n",
    "print(('min_valid_loss', min_loss['tcn_at']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = ['learning_rate', 'dropout_rate', 'num_layers', 'd_model', 'd_ff', 'h']\n",
    "print([(param, best_params['transformer_at'][param]) for param in param_names])\n",
    "print(('min_valid_loss', min_loss['transformer_at']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = ['learning_rate', 'dropout_rate', 'feat_dim', 'decode_num_layers', 'hidden_dim', 'kernel_size', 'N', 'num_map_layers']\n",
    "print([(param, best_params['pyramid_at'][param]) for param in param_names])\n",
    "print(('min_valid_loss', min_loss['pyramid_at']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = ['learning_rate', 'dropout_rate', 'num_layers', 'hidden_dim']\n",
    "print([(param, best_params['nn_at'][param]) for param in param_names])\n",
    "print(('min_valid_loss', min_loss['nn_at']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying Forecasting Horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vary_horizon(directory):\n",
    "    # CNN\n",
    "    lst = os.listdir(directory)\n",
    "    if len(lst)%10 != 0:\n",
    "        lst = sorted(lst)[1:]\n",
    "    else:\n",
    "        lst = sorted(lst)\n",
    "    step = int(len(lst)/10)\n",
    "    horizon_lst = [torch.load(directory + \"/\" + lst[i])[\"min_valid_loss\"] for i in range(len(lst))]\n",
    "    horizon_lst = [np.min(horizon_lst[i-step:i]) for i in range(step, len(lst) + step, step) ]\n",
    "    return sorted(horizon_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#horizon_cnn_at = vary_horizon(\"CNN_AT_horizon\")\n",
    "1.34, 0.71662, 0.7795, 0.69257, 0.58275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_cnn_at[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_cnn_rt = [0.27598, 0.3315, 0.36877, 0.40756, 0.45133, 0.47069, 0.49381, 0.53656 , 0.54284, 0.58275]\n",
    "#horizon_cnn_at = vary_horizon(\"CNN_AT_horizon\")\n",
    "horizon_cnn_at = vary_horizon(\"CNN_AT_horizon\")\n",
    "horizon_lstm = vary_horizon(\"LSTM_AT_horizon\")\n",
    "horizon_trans = vary_horizon(\"Transformer_AT_horizon\")\n",
    "horizon_pyramid = vary_horizon(\"Pyramid_RT_horizon\")\n",
    "horizon_arima = [1.3208365121960388,\n",
    "                 1.3163297457108272,\n",
    "                 1.310415726350439,\n",
    "                 1.306577285185987,\n",
    "                 1.3068774655950486,\n",
    "                 1.3102307160871303,\n",
    "                 1.315505526815925,\n",
    "                 1.3220386706471747,\n",
    "                 1.3306421697079553,\n",
    "                 1.3413983816490263]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_pyramid[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_cnn_rt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(3,31,3))\n",
    "plt.plot(x, horizon_cnn_rt, label = \"CNN_RT\", linewidth = 3)\n",
    "plt.plot(x, horizon_cnn_at, label = \"CNN_AT\", linewidth = 3)\n",
    "#plt.plot(x, horizon_arima, label = \"ARIMA_AT\", linewidth = 3)\n",
    "plt.plot(x, horizon_lstm, label = \"LSTM_AT\", linewidth = 3)\n",
    "plt.plot(x, horizon_trans, label = \"Transformer_AT\", linewidth = 3)\n",
    "plt.plot(x, horizon_pyramid, label = \"Pyramid_RT\", linewidth = 3)\n",
    "plt.xlabel(\"Prediction Steps\", fontsize=12)\n",
    "plt.ylabel(\"RMSE\", fontsize=12)\n",
    "plt.legend(loc = 2)\n",
    "#plt.ylim(0,1.5)\n",
    "plt.title(\"Real Aortic Pressure Data\",fontsize=15)\n",
    "#plt.savefig(\"RMSEs_horizon.png\", dpi = 400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.load(\"/home/rui/KDD/Data/AT_X.pt\")[8000:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(directory):\n",
    "    lst = os.listdir(directory)\n",
    "    lst = sorted(lst)[1:]\n",
    "    lst = [lst[k] for k in range(len(lst)) if \"30\" in lst[k]]\n",
    "    best_rmse = 100\n",
    "    best_model = 0\n",
    "    for i in range(len(lst)):\n",
    "        item = torch.load(directory + \"/\" + lst[i])\n",
    "        if item[\"min_valid_loss\"]  < best_rmse:\n",
    "            best_rmse = item[\"min_valid_loss\"]\n",
    "            best_model = item\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model_cnn_rt = best_model(\"CNN_AT_horizon\")\n",
    "best_model_cnn_at = best_model(\"CNN_AT_horizon\")\n",
    "best_model_lstm = best_model(\"LSTM_AT_horizon\")\n",
    "best_model_trans = best_model(\"Transformer_AT_horizon\")\n",
    "best_model_pyramid = best_model(\"Pyramid_RT_horizon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = 19.481796\n",
    "avg = 84.305374\n",
    "lstm_preds = best_model_lstm[\"preds\"]*std+avg\n",
    "cnn_preds_at = best_model_cnn_at[\"preds\"]*std+avg\n",
    "cnn_preds_rt = torch.load(\"CNN_RT_horizon/genz-30-2.pt\")[\"preds\"]*std+avg\n",
    "pyramid_preds = best_model_pyramid[\"preds\"]*std+avg\n",
    "trans_preds = best_model_trans[\"preds\"].reshape(2000,30)*std+avg\n",
    "# ARIMA\n",
    "arima = np.load(\"ARIMA_AT_preds.npy\")*std+avg\n",
    "true = np.load(\"trues_AT.npy\")*std+avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(lst):\n",
    "    lst = list([np.mean(lst[i:i+3]) for i in range(0, len(lst))])\n",
    "    return np.array(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [350, 360, 620, 940, 970, 1800, 330, 1980, 1870, 1720, 1450, 1290]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = list(range(31,61))\n",
    "pos2 = list(range(1,61))\n",
    "trueline = smooth(np.concatenate([X[index[count]], true[index[count]]]))\n",
    "plt.plot(pos, smooth(trans_preds[index[count]]), label = \"Transformer_AT\")\n",
    "plt.plot(pos, smooth(lstm_preds[:,index[count]]), label = \"LSTM_AT\")\n",
    "plt.plot(pos, smooth(cnn_preds_at[index[count]]), label = \"CNN_AT\")\n",
    "plt.plot(pos, smooth(cnn_preds_rt[index[count]]), label = \"CNN_RT\")\n",
    "plt.plot(pos, smooth(pyramid_preds[index[count]]), label = \"Pyramid_RT\")\n",
    "plt.plot(pos2, trueline, label = \"Ground Truth\", linestyle= \"--\", linewidth = 3)\n",
    "#plt.plot(smooth(true[index[count]]), label = \"Ground Truth\", linestyle= \"--\", linewidth = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15)) \n",
    "#plt.plot(arima[idx]*std+avg, label = \"ARIMA\")\n",
    "count = 0\n",
    "pos = list(range(31,61))\n",
    "pos2 = list(range(1,61))\n",
    "#for i in range(1,5):\n",
    "for count in range(0,12):\n",
    "    plt.subplot(4, 3, count+1)\n",
    "    #print(count)\n",
    "    trueline = smooth(np.concatenate([X[index[count]], true[index[count]]]))\n",
    "    plt.plot(pos,smooth(trans_preds[index[count]]), label = \"Transformer_AT\", linewidth = 3)\n",
    "    plt.plot(pos,smooth(lstm_preds[:,index[count]]), label = \"LSTM_AT\", linewidth = 3)\n",
    "    plt.plot(pos,smooth(cnn_preds_at[index[count]]), label = \"CNN_AT\", linewidth = 3)\n",
    "    plt.plot(pos,smooth(cnn_preds_rt[index[count]]), label = \"CNN_RT\", linewidth = 3)\n",
    "    plt.plot(pos, smooth(pyramid_preds[index[count]]), label = \"Pyramid_RT\", linewidth = 3)\n",
    "    plt.plot(pos2,trueline, label = \"Ground Truth\", linestyle= \"--\", linewidth = 4, color = \"black\")\n",
    "    plt.axvline(x = 30.5, color='black', linestyle = \"--\")\n",
    "    count += 1\n",
    "    if count == 3:\n",
    "        plt.legend(loc=2, bbox_to_anchor=(1, 1.05), fontsize = 15)\n",
    "\n",
    "#plt.savefig(\"Pred_Case.png\", dpi = 400)\n",
    "plt.tight_layout()\n",
    "plt.text(-40, 78, 'Input Steps + Predition Steps', ha='center', fontsize = 20)\n",
    "plt.text(-160, 127, 'Aortic Pressure(mmHg)', va='center', rotation='vertical', fontsize = 20)\n",
    "plt.savefig(\"preds_real.png\", dpi = 600, bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss_cnn_rt, best_params_cnn_rt = Best_Params(\"Results/RT_CNN\")\n",
    "#min_loss_lstm_rt, best_params_lstm_rt = Best_Params(\"Results/RT_LSTM\")\n",
    "#min_loss_trans_rt, best_params_trans_rt = Best_Params2(\"Results/RT_Transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = 83.25376\n",
    "std = 18.252565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rt = np.load(\"Results/preds_ARIMA_RT.npy\")\n",
    "true_rt = np.load(\"Results/trues_ARIMA_RT.npy\")\n",
    "cnn_preds_rt = np.concatenate(torch.load(\"Results/RT_CNN_horizon/genz-60-1.pt\")[\"preds\"], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_preds_rt = np.concatenate(torch.load(\"Results/RT_LSTM_horizon/genz-60-0.pt\")[\"preds\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_preds_rt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "for i in range(len(cnn_preds_rt)):\n",
    "    if np.abs(cnn_preds_rt[i][-1] - cnn_preds_rt[i][0]) > 10/std:\n",
    "        index.append(i)\n",
    "    \n",
    "idx = 30\n",
    "plt.figure(figsize=(15,5)) \n",
    "avg = 82.114876\n",
    "std = 17.022003\n",
    "\n",
    "#plt.plot(arima_rt[index[idx]]*std+avg, label = \"ARIMA\")\n",
    "plt.plot(cnn_preds_rt[index[idx]][:30]*std+avg, label = \"CNN\")\n",
    "#plt.plot(lstm_preds_rt[:,index[idx]]*std+avg, label = \"LSTM\")\n",
    "plt.plot(true_rt[index[idx]][:30]*std+avg, label = \"True\", linestyle= \"--\")\n",
    "plt.legend(loc=2)\n",
    "plt.savefig(\"Case Four.png\", dpi = 400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(best_params_lstm_rt.items())[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vary_horizon2(directory):\n",
    "    # CNN\n",
    "    lst = os.listdir(directory)\n",
    "    lst = sorted(lst)[1:]\n",
    "    horizon_lst = []\n",
    "    for i in range(len(lst)):\n",
    "        horizon_lst.append(torch.load(directory + \"/\" + lst[i])[\"min_valid_loss\"])\n",
    "    return horizon_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_lstm_rt = vary_horizon2(\"Results/RT_LSTM_horizon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_lstm_rt = [0.59899, 0.62331, 0.6054, 0.60684, 0.60, 0.61, 0.612, 0.66, 0.62, 0.60562]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_cnn_rt = vary_horizon2(\"Results/RT_CNN_horizon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_arima_rt = [0.9629866302044089,\n",
    " 0.9708720917980342,\n",
    " 0.9725228657326156,\n",
    " 0.9725916145001904,\n",
    " 0.971447765413801,\n",
    " 0.9701259809733777,\n",
    " 0.9690435077421782,\n",
    " 0.9679333772996392,\n",
    " 0.9666859927240498,\n",
    " 0.9658913494110664]\n",
    "x = list(range(6,61,6))\n",
    "\n",
    "plt.plot(x, horizon_arima_rt, label = \"ARIMA\", linewidth = 3)\n",
    "plt.plot(x, horizon_cnn_rt, label = \"CNN\", linewidth = 3)\n",
    "plt.plot(x, horizon_lstm_rt, label = \"LSTM\", linewidth = 3)\n",
    "plt.legend(loc = 2)\n",
    "plt.xlabel(\"Prediction Steps\", fontsize=12)\n",
    "plt.ylabel(\"RMSE\", fontsize=12)\n",
    "\n",
    "#plt.ylim(0,0.55)\n",
    "plt.title(\"RMSEs for varying forecasting horizons\",fontsize=15)\n",
    "plt.savefig(\"RMSE_horizon_rt.png\", dpi = 400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.load(\"Results/RT_CNN_horizon/genz-60-1.pt\")['model_state_dict']\n",
    "weight1 = weight['input_layer.0.weight']\n",
    "weight2 = weight['input_layer.1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "def plot_kernels(tensor, num_cols=5):\n",
    "    num_kernels = tensor.shape[0]\n",
    "    num_rows = 1+ num_kernels // num_cols\n",
    "    fig = plt.figure(figsize=(num_cols,num_rows))\n",
    "    for i in range(tensor.shape[0]):\n",
    "        ax1 = fig.add_subplot(num_rows,num_cols,i+1)\n",
    "        ax1.imshow(tensor[i])\n",
    "        ax1.axis('off')\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.savefig(\"weight visualization.png\", dpi = 400)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kernels(-np.abs(weight1[:30,:,:].cpu().detach().numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

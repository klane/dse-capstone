{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from torchts.core.spatiotemporal.dcrnn_model import count_parameters\n",
    "from torchts.nn.models.seq2seq import Decoder, Encoder, Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data_x, data_y, out_pos = 0, return_current_avg_std = False):\n",
    "    \"\"\" \n",
    "    Arg:\n",
    "        data_x: features\n",
    "        data_y: labels\n",
    "        out_pos: the position of feature of which average and stand deviation will be returned.\n",
    "    returns:\n",
    "        1. Normalized features and labels\n",
    "        2. Average and standard deviation of the selected feature.\n",
    "    \"\"\"\n",
    "    avg = data_x[:,:,out_pos].mean()\n",
    "    std = data_x[:,:,out_pos].std()\n",
    "#     c_avg = data_x[:,:,1].mean()\n",
    "#     c_std = data_x[:,:,1].std()\n",
    "    for i in range(data_x.shape[-1]):\n",
    "        data_x[:,:,i] = (data_x[:,:,i] - data_x[:,:,i].mean())/data_x[:,:,i].std()\n",
    "    data_y = (data_y-avg)/std\n",
    "    if return_current_avg_std:\n",
    "        return data_x, data_y, (avg, std)  \n",
    "#         return data_x, data_y, (avg, std), (c_avg, c_std)   \n",
    "    else:\n",
    "        return data_x, data_y, (avg, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'traffic_bayArea_station_400001.pkl'\n",
    "\n",
    "with open(filename, \"rb\") as fout:\n",
    "# with open(join(base_dir, filename), \"rb\") as fout:\n",
    "    c_time_series = pickle.load(fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = c_time_series.shape[0]\n",
    "segment_size = c_time_series.shape[1]\n",
    "pred_size = int(segment_size/2)\n",
    "\n",
    "test_size = sample_size // 5\n",
    "train_valid_size = test_size * 4\n",
    "training_size = test_size * 7//2\n",
    "validation_size = test_size * 1//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = c_time_series[:train_valid_size+test_size,:pred_size,:]\n",
    "Y_all = c_time_series[:train_valid_size+test_size,pred_size:,:]\n",
    "\n",
    "X, Y, (avg, std) = scale_data(X_all, Y_all, out_pos = 0, return_current_avg_std = True)\n",
    "X, Y = X.float(), Y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "dropout_rate = 0.6\n",
    "num_layers = 1\n",
    "hidden_dim = 128\n",
    "\n",
    "input_steps = segment_size\n",
    "output_steps = segment_size\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "\n",
    "train_idx = list(range(training_size))\n",
    "valid_idx = list(range(training_size, train_valid_size))\n",
    "test_idx = list(range(train_valid_size, train_valid_size + test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_set = TensorDataset(X[train_idx], Y[train_idx])\n",
    "valid_set = TensorDataset(X[valid_idx], Y[valid_idx])\n",
    "test_set = TensorDataset(X[test_idx], Y[test_idx])\n",
    "\n",
    "train_generator = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_generator = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n",
    "test_generator = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = list(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = d[0][0]\n",
    "target_tensor = d[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/capstone/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "horizon = target_tensor.shape[1]\n",
    "output_dim = target_tensor.shape[-1]\n",
    "\n",
    "encoder = Encoder(input_size, hidden_dim, num_layers, dropout_rate)\n",
    "decoder = Decoder(output_size, hidden_dim, num_layers, dropout_rate)\n",
    "\n",
    "model = Seq2Seq(\n",
    "    encoder,\n",
    "    decoder,\n",
    "    output_dim,\n",
    "    horizon,\n",
    "    optimizer=optim.RMSprop,\n",
    "    optimizer_args={'lr': 0.01},\n",
    "    scheduler=optim.lr_scheduler.StepLR,\n",
    "    scheduler_args={'step_size': 5, 'gamma': 0.8},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399617"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 36, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1955, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.criterion(output, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/usr/local/Caskroom/miniconda/base/envs/capstone/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 134 K \n",
      "1 | decoder | Decoder | 265 K \n",
      "------------------------------------\n",
      "399 K     Trainable params\n",
      "0         Non-trainable params\n",
      "399 K     Total params\n",
      "1.598     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/capstone/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8bb8ac79455457bb79299e808d8fe70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/capstone/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=5)\n",
    "trainer.fit(model, train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

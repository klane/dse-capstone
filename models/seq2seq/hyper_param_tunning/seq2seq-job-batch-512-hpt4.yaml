apiVersion: batch/v1
kind: Job
metadata:
  name: seq2seq-job-batchsize-512-hpt4
spec:
  template:
    spec:
      containers:
      - name: demo
        # image: gitlab-registry.nautilus.optiputer.net/prp/jupyterlab
        image: gitlab-registry.nautilus.optiputer.net/akashshah59/torchts-docker
        # command: ["/bin/sh","-c"]
        # args: ["python /opt/repo/Nautilus-seq2seq/main-test.py; kubectl cp models-vol/test_dataframe.csv ./test_dataframe.csv"]
        command: 
          - "python"
        args: 
          - "/opt/repo/Nautilus-seq2seq/main_batchsize_512_hpt4.py"
          # - "/opt/repo/Nautilus-seq2seq/main-test.py"
        volumeMounts:
        - name: git-repo
          mountPath: /opt/repo
        - name: models-vol4
          mountPath: /models-vol4
        resources:
          limits:
            memory: 32Gi
            cpu: "6"
            nvidia.com/gpu: "1"
          requests:
            memory: 24Gi
            cpu: "1"
            nvidia.com/gpu: "1"   
      initContainers:
      - name: init-clone-repo
        image: alpine/git
        args:
          - clone
          - --single-branch
          - https://gitlab.nautilus.optiputer.net/raulgiovannymartinez/Nautilus-seq2seq
          - /opt/repo/Nautilus-seq2seq
        volumeMounts:
        - name: git-repo
          mountPath: /opt/repo
      volumes:
      - name: models-vol4
        persistentVolumeClaim:
          claimName: models-vol4
      - name: git-repo
        emptyDir: {}
      restartPolicy: Never
      # affinity:
      #   nodeAffinity:
      #     requiredDuringSchedulingIgnoredDuringExecution:
      #       nodeSelectorTerms:
      #       - matchExpressions:
      #         - key: gpu-type
      #           operator: In
      #           values:
      #           - 2080Ti
  backoffLimit: 3

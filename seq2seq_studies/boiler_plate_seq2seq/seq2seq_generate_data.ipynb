{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sal\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156328, 4)\n",
      "Wall time: 2.97 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>station</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>total_flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:05:00</td>\n",
       "      <td>400001</td>\n",
       "      <td>71.7</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 00:05:00</td>\n",
       "      <td>400714</td>\n",
       "      <td>71.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 00:05:00</td>\n",
       "      <td>400743</td>\n",
       "      <td>68.8</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 00:10:00</td>\n",
       "      <td>400001</td>\n",
       "      <td>71.7</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 00:10:00</td>\n",
       "      <td>400714</td>\n",
       "      <td>70.6</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  station  avg_speed  total_flow\n",
       "0 2020-01-01 00:05:00   400001       71.7        57.0\n",
       "1 2020-01-01 00:05:00   400714       71.0        61.0\n",
       "2 2020-01-01 00:05:00   400743       68.8       111.0\n",
       "3 2020-01-01 00:10:00   400001       71.7        47.0\n",
       "4 2020-01-01 00:10:00   400714       70.6        63.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#parameters of the AWS database\n",
    "endpoint = \"capstone.clihskgj8i7s.us-west-2.rds.amazonaws.com\"\n",
    "user=\"group3\"\n",
    "db=\"db1\"\n",
    "#pw=getpass.getpass(\"Enter database password\")\n",
    "pw=open(r'C:\\Users\\rmartinez4\\OneDrive - Illumina, Inc\\Desktop\\password.txt',\"r\").read().rstrip()\n",
    "\n",
    "engine = sal.create_engine('postgresql://%s:%s@%s/%s' % (user, pw, endpoint, db))\n",
    "\n",
    "# query=\"\"\"\n",
    "# select timestamp, station, total_flow\n",
    "# from traffic_train\n",
    "# ;\n",
    "# \"\"\"\n",
    "\n",
    "query=\"\"\"\n",
    "select timestamp, station, avg_speed, total_flow\n",
    "from traffic_train\n",
    "where station in (400714, 400743, 400001)\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "df_query_raw=pd.read_sql(query, engine)\n",
    "\n",
    "print(df_query_raw.shape)\n",
    "df_query_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp      0\n",
       "station        0\n",
       "avg_speed     17\n",
       "total_flow    17\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query_raw.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na values with rolling mean\n",
    "df_query_cleaned = df_query_raw.fillna(df_query_raw.rolling(window=6,min_periods=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp     0\n",
       "station       0\n",
       "avg_speed     0\n",
       "total_flow    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq2seq_data_4dim(df, horizon, window, features):\n",
    "    \n",
    "    idx_cols = ['station','timestamp']\n",
    "\n",
    "    df = df.set_index(idx_cols).sort_values(by=idx_cols)\n",
    "\n",
    "    features_tensor_list = []\n",
    "    for f in features:\n",
    "        print(f)\n",
    "        \n",
    "        ts_seq_list = []\n",
    "        for s in df.index.unique(level=0):\n",
    "            print(s)\n",
    "            values = df.loc[s][f].values\n",
    "\n",
    "            for i in range(len(values)-horizon*2):\n",
    "                arr = np.array(values[i:i+horizon*2])\n",
    "                ts_seq_list.append(torch.from_numpy(arr.reshape(horizon*2,1)))\n",
    "\n",
    "        sequence_tensor = torch.stack(ts_seq_list, dim=0)\n",
    "        sequence_tensor = torch.reshape(sequence_tensor, tuple(sequence_tensor.shape)+(1,))\n",
    "\n",
    "        features_tensor_list.append(sequence_tensor)\n",
    "\n",
    "    return torch.cat(features_tensor_list, dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq2seq_data(df, horizon, window, features):\n",
    "    \n",
    "    idx_cols = ['station','timestamp']\n",
    "\n",
    "    df = df.set_index(idx_cols).sort_values(by=idx_cols)\n",
    "\n",
    "    features_tensor_list = []\n",
    "    for f in features:\n",
    "        print(f)\n",
    "        \n",
    "        ts_seq_list = []\n",
    "        for s in df.index.unique(level=0):\n",
    "            print(s)\n",
    "            values = df.loc[s][f].values\n",
    "\n",
    "            for i in range(len(values)-horizon*2):\n",
    "                arr = np.array(values[i:i+horizon*2])\n",
    "                ts_seq_list.append(torch.from_numpy(arr.reshape(horizon*2,1)))\n",
    "\n",
    "        sequence_tensor = torch.stack(ts_seq_list, dim=0)\n",
    "\n",
    "        features_tensor_list.append(sequence_tensor)\n",
    "\n",
    "    return torch.cat(features_tensor_list, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_speed\n",
      "400001\n",
      "400714\n",
      "400743\n",
      "torch.Size([156256, 24, 1])\n",
      "Wall time: 1.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_seq2seq = generate_seq2seq_data(df_query_cleaned,\n",
    "                                     horizon=12, \n",
    "                                     window=1, \n",
    "#                                     features=['avg_speed', 'total_flow'])\n",
    "                                     features=['avg_speed'])\n",
    "\n",
    "print(data_seq2seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([156256, 12, 1]) torch.Size([156256, 12, 1])\n"
     ]
    }
   ],
   "source": [
    "x = data_seq2seq[:, :12, :]\n",
    "y = data_seq2seq[:, 12:, :]\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156256 31251 109379 15626\n"
     ]
    }
   ],
   "source": [
    "num_samples = x.shape[0]\n",
    "num_test = round(num_samples * 0.2)\n",
    "num_train = round(num_samples * 0.7)\n",
    "num_val = num_samples - num_test - num_train\n",
    "\n",
    "print(num_samples, num_test, num_train, num_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([109379, 12, 1]) torch.Size([109379, 12, 1])\n",
      "torch.Size([15626, 12, 1]) torch.Size([15626, 12, 1])\n",
      "torch.Size([31251, 12, 1]) torch.Size([31251, 12, 1])\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "x_train, y_train = x[:num_train], y[:num_train]\n",
    "\n",
    "# val\n",
    "x_val, y_val = (\n",
    "    x[num_train: num_train + num_val],\n",
    "    y[num_train: num_train + num_val],\n",
    ")\n",
    "\n",
    "# test\n",
    "x_test, y_test = x[-num_test:], y[-num_test:]\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train x:  torch.Size([109379, 12, 1]) y: torch.Size([109379, 12, 1])\n",
      "val x:  torch.Size([15626, 12, 1]) y: torch.Size([15626, 12, 1])\n",
      "test x:  torch.Size([31251, 12, 1]) y: torch.Size([31251, 12, 1])\n"
     ]
    }
   ],
   "source": [
    "output_dir = r'C:\\Users\\rmartinez4\\Box\\Personal Git\\Nautilus-seq2seq\\boiler_plate_seq2seq'\n",
    "\n",
    "for cat in [\"train\", \"val\", \"test\"]:\n",
    "    _x, _y = locals()[\"x_\" + cat], locals()[\"y_\" + cat]\n",
    "    print(cat, \"x: \", _x.shape, \"y:\", _y.shape)\n",
    "    np.savez_compressed(\n",
    "        join(output_dir, \"%s.npz\" % cat),\n",
    "        x=_x,\n",
    "        y=_y\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

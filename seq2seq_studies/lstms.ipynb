{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join, abspath\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from scipy.signal import tukey\n",
    "from torch.utils import data\n",
    "from tqdm.notebook import tqdm\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "IMG_DIR = '/home/eliza/mlhc/imgs'\n",
    "DIR = abspath('RT_Cases_NU_HRPCI')\n",
    "PREPROCESS_DIR = abspath('../data/data')\n",
    "CONTINOUS_DIR = join(PREPROCESS_DIR, 'continuous')\n",
    "WINDOW_SIZE = 15000\n",
    "STEP_SIZE = 250\n",
    "MIN_VALID_AOP = 50\n",
    "MAX_VALID_AOP = 200\n",
    "SLICES_DIR = join(PREPROCESS_DIR, 'slices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data_x, data_y, out_pos = 0, return_current_avg_std = False):\n",
    "    \"\"\" \n",
    "    Arg:\n",
    "        data_x: features\n",
    "        data_y: labels\n",
    "        out_pos: the position of feature of which average and stand deviation will be returned.\n",
    "    returns:\n",
    "        1. Normalized features and labels\n",
    "        2. Average and standard deviation of the selected feature.\n",
    "    \"\"\"\n",
    "    avg = data_x[:,:,out_pos].mean()\n",
    "    std = data_x[:,:,out_pos].std()\n",
    "    c_avg = data_x[:,:,1].mean()\n",
    "    c_std = data_x[:,:,1].std()\n",
    "    for i in range(data_x.shape[-1]):\n",
    "        data_x[:,:,i] = (data_x[:,:,i] - data_x[:,:,i].mean())/data_x[:,:,i].std()\n",
    "    data_y = (data_y-avg)/std\n",
    "    if return_current_avg_std:\n",
    "        return data_x, data_y, (avg, std), (c_avg, c_std)   \n",
    "    else:\n",
    "        return data_x, data_y, (avg, std)\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, X, Y, lst_index, output_steps, position_embedding = (False)):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            lst_index: indexes of observations in the dataset.\n",
    "            output_steps: Forecasting Horizon.\n",
    "        \"\"\"\n",
    "        self.X = X[lst_index]\n",
    "        self.Y = Y[lst_index]\n",
    "        self.output_steps = output_steps\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.X[index]\n",
    "        y = self.Y[index][:self.output_steps]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREND = 'ids' # id, is, ds\n",
    "X_train = torch.load(os.path.abspath('../data/data/at_train_10min/%s_x_train' % TREND))\n",
    "Y_train = torch.load(os.path.abspath('../data/data/at_train_10min/%s_y_train' % TREND))\n",
    "sample_size, pred_length, feature_count = X_train.shape\n",
    "\n",
    "TEST_TREND = 'ids'\n",
    "X_test = torch.load(os.path.abspath('../data/data/at_test_10min/%s_x_test' % TEST_TREND))\n",
    "Y_test = torch.load(os.path.abspath('../data/data/at_test_10min/%s_y_test' % TEST_TREND))\n",
    "test_input_size = X_test.shape[0]\n",
    "\n",
    "TUNING = False  \n",
    "test_size = 1000 if TUNING else min(sample_size // 4 * 1, test_input_size)\n",
    "train_valid_size = test_size * 4\n",
    "training_size = test_size * 3\n",
    "validation_size = test_size * 1\n",
    "print('Total: %d\\nTraining: %d, Validation: %d, Test: %d' % (train_valid_size, training_size, validation_size, test_size))\n",
    "print('Test set: %d ~ %d'% (test_input_size-test_size, test_input_size))\n",
    "\n",
    "X_all = torch.cat([X_train[:train_valid_size], X_test[test_input_size-test_size: test_input_size]])\n",
    "Y_all = torch.cat([Y_train[:train_valid_size], Y_test[test_input_size-test_size: test_input_size]])\n",
    "X, Y, (avg, std), (c_avg, c_std) = scale_data(X_all, Y_all, out_pos = 0, return_current_avg_std = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout_rate):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim: the dimension of input sequences.\n",
    "            hidden_dim: number hidden units.\n",
    "            num_layers: number of encode layers.\n",
    "            dropout_rate: recurrent dropout rate.\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, \n",
    "                            bidirectional = True, dropout = dropout_rate, batch_first = True)\n",
    "        \n",
    "    def forward(self, source):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            source: input tensor(batch_size*input dimension)\n",
    "        Return:\n",
    "            outputs: Prediction\n",
    "            concat_hidden: hidden states\n",
    "        \"\"\"\n",
    "        outputs, hidden = self.lstm(source)\n",
    "        return outputs, hidden\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, num_layers, dropout_rate):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            output_dim: the dimension of output sequences.\n",
    "            hidden_dim: number hidden units.\n",
    "            num_layers: number of code layers.\n",
    "            dropout_rate: recurrent dropout rate.\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # Since the encoder is bidirectional, decoder has double hidden size\n",
    "        self.lstm = nn.LSTM(output_dim, hidden_dim*2, num_layers = num_layers, \n",
    "                            dropout = dropout_rate, batch_first = True)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_dim*2, output_dim)\n",
    "      \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: prediction from previous prediction.\n",
    "            hidden: hidden states from previous cell.\n",
    "        Returns:\n",
    "            1. prediction for current step.\n",
    "            2. hidden state pass to next cell.\n",
    "        \"\"\"\n",
    "        output, hidden = self.lstm(x, hidden)   \n",
    "        prediction = self.out(output.float())\n",
    "        return prediction, hidden     \n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encoder: Encoder object.\n",
    "            decoder: Decoder object.\n",
    "            device: \n",
    "        \"\"\"\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, source, target_tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            source: input tensor.\n",
    "            target_length: forecasting steps.\n",
    "        Returns:\n",
    "            total prediction\n",
    "        \"\"\"\n",
    "        batch_size = source.size(0) \n",
    "        input_length = source.size(1) \n",
    "        target_length = target_tensor.shape[1]\n",
    "        output_dim = target_tensor.shape[-1]\n",
    "        encoder_hidden = (torch.zeros(self.encoder.num_layers*2, batch_size, self.encoder.hidden_dim, device=device),\n",
    "                          torch.zeros(self.encoder.num_layers*2, batch_size, self.encoder.hidden_dim, device=device))\n",
    "        encoder_output, encoder_hidden = self.encoder(source)\n",
    "        \n",
    "        # Concatenate the hidden states of both directions.\n",
    "        num_layers = int(encoder_hidden[0].shape[0]/2)\n",
    "        h = torch.cat([encoder_hidden[0][0:self.encoder.num_layers,:,:], \n",
    "                       encoder_hidden[0][-self.encoder.num_layers:,:,:]], \n",
    "                      dim=2, out=None).to(device)\n",
    "        c = torch.cat([encoder_hidden[1][0:self.encoder.num_layers,:,:], \n",
    "                       encoder_hidden[1][-self.encoder.num_layers:,:,:]], \n",
    "                      dim=2, out=None).to(device)\n",
    "        concat_hidden = (h, c)\n",
    "        \n",
    "        \n",
    "        outputs = torch.zeros(batch_size, target_length, output_dim).to(self.device)\n",
    "        decoder_output = torch.zeros((batch_size, 1, output_dim), device = self.device)\n",
    "        decoder_hidden = concat_hidden\n",
    "        \n",
    "        for t in range(target_length):  \n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_output, decoder_hidden)\n",
    "            outputs[:,t:t+1,:] = decoder_output\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch_train(model, data_generator, model_optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: RNN model.\n",
    "        data_generator: data.DataLoader object.\n",
    "        model_optimizer: optimizer.\n",
    "        criterion: loss function\n",
    "    Returns:\n",
    "        Root Mean Square Error on Training Dataset\n",
    "    \"\"\"\n",
    "    MSE = []\n",
    "    for x, y in data_generator:\n",
    "        # The input shape for nn.conv1d should sequence_length * batch_size * #features\n",
    "        input_tensor, target_tensor = x.to(device).float(), y.to(device).float()\n",
    "        model_optimizer.zero_grad()\n",
    "        loss = 0\n",
    "        output = model(input_tensor, target_tensor).reshape(target_tensor.shape)\n",
    "        num_iter = output.size(0)\n",
    "        for ot in range(num_iter):\n",
    "            loss += criterion(output[ot], target_tensor[ot])\n",
    "        MSE.append(loss.item()/num_iter)\n",
    "        loss.backward()\n",
    "        model_optimizer.step()\n",
    "    \n",
    "    return round(np.sqrt(np.mean(MSE)), 5)\n",
    " \n",
    "\n",
    "def run_epoch_eval(model, data_generator, criterion, return_pred = False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: CNN model.\n",
    "        data_generator: data.DataLoader object.\n",
    "        criterion: loss function\n",
    "    Returns:\n",
    "        Root Mean Square Error on evaluation datasets.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        MSE = []\n",
    "        preds = []\n",
    "        for x, y in data_generator:\n",
    "            input_tensor, target_tensor = x.to(device).float(), y.to(device).float()\n",
    "            loss = 0\n",
    "            output = model(input_tensor, target_tensor).reshape(target_tensor.shape)\n",
    "            preds.append(output.cpu().detach().numpy())\n",
    "            num_iter = output.size(0)\n",
    "            \n",
    "            for ot in range(num_iter):\n",
    "                loss += criterion(output[ot], target_tensor[ot])\n",
    "            MSE.append(loss.item()/num_iter)\n",
    "            \n",
    "    if return_pred == True:\n",
    "        preds =  np.concatenate(preds).squeeze(-1)\n",
    "        return round(np.sqrt(np.mean(MSE)), 5), preds\n",
    "    else:\n",
    "        return round(np.sqrt(np.mean(MSE)), 5)\n",
    "\n",
    "\n",
    "def train_model(model, X, Y, learning_rate, output_steps, batch_size, train_idx, valid_idx, test_idx, test=False, return_pred=False):\n",
    "    # Initialize the model and define optimizer, learning rate decay and criterion\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 5, gamma=0.8)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Split dataset into training set, validation set and test set.\n",
    "    train_rmse, train_set = [], Dataset(X, Y, train_idx, output_steps)\n",
    "    valid_rmse, valid_set = [], Dataset(X, Y, valid_idx, output_steps)\n",
    "    if test:\n",
    "        test_rmse, test_set = [], Dataset(X, Y, test_idx, output_steps)\n",
    "    \n",
    "    min_loss = 1000\n",
    "    best_model = 0\n",
    "    best_preds = 0\n",
    "    min_valid_loss = 1000\n",
    "    \n",
    "    for i in tqdm(range(200)):\n",
    "        start = time.time()\n",
    "        scheduler.step()\n",
    "        train_generator = data.DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "        valid_generator = data.DataLoader(valid_set, batch_size = batch_size, shuffle = False)\n",
    "        if test:\n",
    "            test_generator = data.DataLoader(test_set, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "        model.train()\n",
    "        train_rmse.append(run_epoch_train(model, train_generator, optimizer, criterion))\n",
    "            \n",
    "        model.eval()\n",
    "        rmse, predictions = run_epoch_eval(model,  valid_generator, criterion, return_pred = True)\n",
    "        valid_rmse.append(rmse)\n",
    "        \n",
    "        if test:\n",
    "            if return_pred:\n",
    "                t_rmse, test_predictions = run_epoch_eval(model, test_generator, criterion, return_pred = True)\n",
    "            else:\n",
    "                t_rmse = run_epoch_eval(model, test_generator, criterion, return_pred = False)\n",
    "            test_rmse.append(t_rmse)\n",
    "        \n",
    "        if valid_rmse[-1] < min_loss:\n",
    "            min_loss = valid_rmse[-1]\n",
    "            best_model = model\n",
    "            min_valid_loss = valid_rmse[-1]\n",
    "            best_preds = predictions\n",
    "            min_valid_loss = valid_rmse[-1]\n",
    "            \n",
    "        if (len(train_rmse) > 15 and np.mean(valid_rmse[-5:]) >= np.mean(valid_rmse[-10:-5])):\n",
    "            break\n",
    "            \n",
    "    end = time.time()       \n",
    "    print((\"Epoch %d:\"%(i+1)), (\"Loss: %f; \"%train_rmse[-1]),(\"valid_loss: %f; \"%valid_rmse[-1]), \n",
    "          (\"Time: %f; \"%round(end - start,5)))\n",
    "\n",
    "    if test:\n",
    "        if return_pred:\n",
    "            return best_model, (train_rmse,valid_rmse),  best_preds, min_valid_loss, test_rmse, test_predictions\n",
    "        return best_model, (train_rmse,valid_rmse),  best_preds, min_valid_loss, test_rmse\n",
    "    return best_model, (train_rmse,valid_rmse),  best_preds, min_valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "dropout_rate = 0.6\n",
    "num_layers = 1\n",
    "hidden_dim = 128\n",
    "\n",
    "input_steps = 60\n",
    "output_steps = 60\n",
    "input_size = 2\n",
    "output_size = 1\n",
    "\n",
    "train_idx = list(range(training_size))\n",
    "valid_idx = list(range(training_size, train_valid_size))\n",
    "test_idx = list(range(train_valid_size, train_valid_size + test_size))\n",
    "\n",
    "encoder = Encoder(input_size, hidden_dim, num_layers, dropout_rate)\n",
    "decoder = Decoder(output_size, hidden_dim, num_layers, dropout_rate)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "model, loss, preds, min_valid_loss, test_rmse = train_model(\n",
    "    model, X, Y, learning_rate, output_steps = output_steps, batch_size = 64,\n",
    "    train_idx = train_idx, valid_idx = valid_idx, test_idx = test_idx, test=True)\n",
    "\n",
    "print({\n",
    "    'learning_rate': learning_rate,\n",
    "    'dropout_rate': dropout_rate,\n",
    "    'num_layers':num_layers,\n",
    "    'hidden_dim': hidden_dim,\n",
    "#     'model_state_dict': model.state_dict(),\n",
    "#     'loss': loss,\n",
    "    'min_valid_loss': min_valid_loss,\n",
    "#     'preds':preds,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'learning_rate': learning_rate,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'num_layers':num_layers,\n",
    "            'hidden_dim': hidden_dim,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'loss': loss,\n",
    "            'min_valid_loss': min_valid_loss,\n",
    "            'preds':preds,\n",
    "#             'test_preds': test_preds,\n",
    "            },\"/home/eliza/mlhc/tune/horizon/lstms_at/aop_at_10min.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse, valid_rmse = loss\n",
    "plt.plot(valid_rmse)\n",
    "plt.plot(test_rmse)\n",
    "print('Train: %s, Test: %s, Test RMSE: %f' % (TREND, TEST_TREND, test_rmse[-1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_with_avg_std(data_x, data_y, avg, std, c_avg, c_std):\n",
    "    data_x[:,:,0] = (data_x[:,:,0] - avg)/std\n",
    "    data_x[:,:,1] = (data_x[:,:,1] - c_avg)/c_std\n",
    "    data_y = (data_y-avg)/std\n",
    "    return data_x, data_y\n",
    "\n",
    "t_rmse_trend_dict = {}\n",
    "def test_trend(trend):\n",
    "    X_test_trend = torch.load(os.path.abspath('../data/data/at_test_10min/%s_x_test' % trend))[test_input_size-test_size: test_input_size]\n",
    "    Y_test_trend = torch.load(os.path.abspath('../data/data/at_test_10min/%s_y_test' % trend))[test_input_size-test_size: test_input_size]\n",
    "    X_test_trend, Y_test_trend = scale_with_avg_std(X_test_trend, Y_test_trend, avg, std, c_avg, c_std)\n",
    "    test_trend_size = Y_test_trend.shape[0]\n",
    "    criterion = nn.MSELoss()\n",
    "    test_rmse, test_set = [], Dataset(X_test_trend, Y_test_trend, np.array(range(test_trend_size)), output_steps)\n",
    "    test_generator = data.DataLoader(test_set, batch_size = 64, shuffle = False)\n",
    "    t_rmse_trend, test_predictions_trend = run_epoch_eval(model, test_generator, criterion, return_pred = True)\n",
    "    t_rmse_trend_dict[trend] = t_rmse_trend\n",
    "    \n",
    "for trend in ['i', 'd', 's']:\n",
    "    test_trend(trend)\n",
    "print('Train: %s, test rmse: %s' % (TREND, t_rmse_trend_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on I, D, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_with_avg_std(data_x, data_y, avg, std, c_avg, c_std):\n",
    "    data_x[:,:,0] = (data_x[:,:,0] - avg)/std\n",
    "    data_x[:,:,1] = (data_x[:,:,1] - c_avg)/c_std\n",
    "    data_y = (data_y-avg)/std\n",
    "    return data_x, data_y\n",
    "\n",
    "t_rmse_trend_dict = {}\n",
    "def test_trend(trend):\n",
    "    X_test_trend = torch.load(os.path.abspath('../data/data/at_test/%s_x_test' % trend))[: test_size]\n",
    "    Y_test_trend = torch.load(os.path.abspath('../data/data/at_test/%s_y_test' % trend))[: test_size]\n",
    "    X_test_trend, Y_test_trend = scale_with_avg_std(X_test_trend, Y_test_trend, avg, std, c_avg, c_std)\n",
    "    test_trend_size = Y_test_trend.shape[0]\n",
    "    criterion = nn.MSELoss()\n",
    "    test_rmse, test_set = [], Dataset(X_test_trend, Y_test_trend, np.array(range(test_trend_size)), output_steps)\n",
    "    test_generator = data.DataLoader(test_set, batch_size = 64, shuffle = False)\n",
    "    t_rmse_trend, test_predictions_trend = run_epoch_eval(model, test_generator, criterion, return_pred = True)\n",
    "    t_rmse_trend_dict[trend] = t_rmse_trend\n",
    "    \n",
    "for trend in ['i', 'd', 's']:\n",
    "    test_trend(trend)\n",
    "print('Train: %s, test rmse: %s' % (TREND, t_rmse_trend_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_rmse_dict = {}\n",
    "existing_cycles = [int(cycle_count) for cycle_count in os.listdir(\"/home/eliza/mlhc/tune/rmse/lstm_at\")]\n",
    "CYCLE = 0 if len(existing_cycles) == 0 else int(sorted(existing_cycles)[-1]) + 1\n",
    "LSTM_RMSE_DIR = \"/home/eliza/mlhc/tune/rmse/lstm_at/{}\".format(CYCLE)\n",
    "if not os.path.exists(LSTM_RMSE_DIR):\n",
    "    os.makedirs(LSTM_RMSE_DIR)\n",
    "print('Save cycle as: {}'.format(CYCLE))\n",
    "\n",
    "if os.path.exists(join(LSTM_RMSE_DIR, 'aop.pt')):\n",
    "    lstm_rmse_dict = torch.load(join(LSTM_RMSE_DIR, 'aop.pt'))\n",
    "lstm_rmse_dict[TREND] = [test_rmse[-1], t_rmse_trend_dict['i'], t_rmse_trend_dict['d'], t_rmse_trend_dict['s']]\n",
    "torch.save(lstm_rmse_dict, join(LSTM_RMSE_DIR, 'aop.pt'))\n",
    "torch.load(join(LSTM_RMSE_DIR, 'aop.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning rate': [0.1,0.01, 0.001, 0.0001],\n",
    "    'dropout_rate': list(np.linspace(0.2, 0.8, 4)),\n",
    "#     'num_layers': list(range(1,4)),\n",
    "    'hidden_dim': list(range(64, 512, 64)),\n",
    "}\n",
    "com = 1\n",
    "for x in param_grid.values():\n",
    "    com *= len(x)\n",
    "# Only use 20 percent of total number of combinations\n",
    "max_evals = int(com*0.2)\n",
    "random_params = {k: random.sample(v, 1)[0] for k, v in param_grid.items()}\n",
    "learning_rate = random_params[\"learning rate\"]\n",
    "dropout_rate = random_params[\"dropout_rate\"]\n",
    "# num_layers = random_params[\"num_layers\"]\n",
    "hidden_dim = random_params[\"hidden_dim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64, 128, 192, 256, 320, 384, 448]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(64, 512, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_params_dict = {}\n",
    "for i in range(0, max_evals):\n",
    "    random_params_dict[i] = {k: random.sample(v, 1)[0] for k, v in param_grid.items()}\n",
    "# print(random_params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'learning rate': 0.01, 'dropout_rate': 0.8, 'hidden_dim': 384},\n",
       " 1: {'learning rate': 0.001, 'dropout_rate': 0.4, 'hidden_dim': 192},\n",
       " 2: {'learning rate': 0.01, 'dropout_rate': 0.4, 'hidden_dim': 192},\n",
       " 3: {'learning rate': 0.01, 'dropout_rate': 0.2, 'hidden_dim': 128},\n",
       " 4: {'learning rate': 0.1, 'dropout_rate': 0.4, 'hidden_dim': 384},\n",
       " 5: {'learning rate': 0.001, 'dropout_rate': 0.8, 'hidden_dim': 448},\n",
       " 6: {'learning rate': 0.0001, 'dropout_rate': 0.2, 'hidden_dim': 64},\n",
       " 7: {'learning rate': 0.0001, 'dropout_rate': 0.4, 'hidden_dim': 384},\n",
       " 8: {'learning rate': 0.001,\n",
       "  'dropout_rate': 0.6000000000000001,\n",
       "  'hidden_dim': 384},\n",
       " 9: {'learning rate': 0.01,\n",
       "  'dropout_rate': 0.6000000000000001,\n",
       "  'hidden_dim': 256},\n",
       " 10: {'learning rate': 0.01, 'dropout_rate': 0.4, 'hidden_dim': 256},\n",
       " 11: {'learning rate': 0.01, 'dropout_rate': 0.4, 'hidden_dim': 320},\n",
       " 12: {'learning rate': 0.001,\n",
       "  'dropout_rate': 0.6000000000000001,\n",
       "  'hidden_dim': 256},\n",
       " 13: {'learning rate': 0.0001, 'dropout_rate': 0.4, 'hidden_dim': 448},\n",
       " 14: {'learning rate': 0.001, 'dropout_rate': 0.4, 'hidden_dim': 128},\n",
       " 15: {'learning rate': 0.1,\n",
       "  'dropout_rate': 0.6000000000000001,\n",
       "  'hidden_dim': 256},\n",
       " 16: {'learning rate': 0.1, 'dropout_rate': 0.8, 'hidden_dim': 128},\n",
       " 17: {'learning rate': 0.0001, 'dropout_rate': 0.8, 'hidden_dim': 64},\n",
       " 18: {'learning rate': 0.0001, 'dropout_rate': 0.4, 'hidden_dim': 320},\n",
       " 19: {'learning rate': 0.1, 'dropout_rate': 0.2, 'hidden_dim': 64},\n",
       " 20: {'learning rate': 0.1,\n",
       "  'dropout_rate': 0.6000000000000001,\n",
       "  'hidden_dim': 256},\n",
       " 21: {'learning rate': 0.1, 'dropout_rate': 0.4, 'hidden_dim': 192}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_params_dict = {0: {u'learning rate': 0.001, u'dropout_rate': 0.2, u'hidden_dim': 128, u'num_layers': 1}, 1: {u'learning rate': 0.001, u'dropout_rate': 0.4, u'hidden_dim': 320, u'num_layers': 3}, 2: {u'learning rate': 0.1, u'dropout_rate': 0.8, u'hidden_dim': 384, u'num_layers': 2}, 3: {u'learning rate': 0.01, u'dropout_rate': 0.2, u'hidden_dim': 448, u'num_layers': 3}, 4: {u'learning rate': 0.001, u'dropout_rate': 0.6000000000000001, u'hidden_dim': 192, u'num_layers': 2}, 5: {u'learning rate': 0.01, u'dropout_rate': 0.6000000000000001, u'hidden_dim': 256, u'num_layers': 3}, 6: {u'learning rate': 0.1, u'dropout_rate': 0.4, u'hidden_dim': 192, u'num_layers': 1}, 7: {u'learning rate': 0.01, u'dropout_rate': 0.8, u'hidden_dim': 448, u'num_layers': 3}, 8: {u'learning rate': 0.1, u'dropout_rate': 0.8, u'hidden_dim': 128, u'num_layers': 1}, 9: {u'learning rate': 0.001, u'dropout_rate': 0.6000000000000001, u'hidden_dim': 192, u'num_layers': 3}, 10: {u'learning rate': 0.0001, u'dropout_rate': 0.6000000000000001, u'hidden_dim': 256, u'num_layers': 2}, 11: {u'learning rate': 0.0001, u'dropout_rate': 0.2, u'hidden_dim': 64, u'num_layers': 3}, 12: {u'learning rate': 0.0001, u'dropout_rate': 0.8, u'hidden_dim': 128, u'num_layers': 1}, 13: {u'learning rate': 0.1, u'dropout_rate': 0.8, u'hidden_dim': 448, u'num_layers': 1}, 14: {u'learning rate': 0.001, u'dropout_rate': 0.8, u'hidden_dim': 192, u'num_layers': 1}, 15: {u'learning rate': 0.001, u'dropout_rate': 0.8, u'hidden_dim': 448, u'num_layers': 3}, 16: {u'learning rate': 0.1, u'dropout_rate': 0.8, u'hidden_dim': 64, u'num_layers': 3}, 17: {u'learning rate': 0.1, u'dropout_rate': 0.8, u'hidden_dim': 128, u'num_layers': 1}, 18: {u'learning rate': 0.0001, u'dropout_rate': 0.4, u'hidden_dim': 448, u'num_layers': 1}, 19: {u'learning rate': 0.0001, u'dropout_rate': 0.8, u'hidden_dim': 64, u'num_layers': 1}, 20: {u'learning rate': 0.0001, u'dropout_rate': 0.4, u'hidden_dim': 128, u'num_layers': 1}, 21: {u'learning rate': 0.01, u'dropout_rate': 0.8, u'hidden_dim': 256, u'num_layers': 1}, 22: {u'learning rate': 0.0001, u'dropout_rate': 0.2, u'hidden_dim': 256, u'num_layers': 1}, 23: {u'learning rate': 0.1, u'dropout_rate': 0.4, u'hidden_dim': 192, u'num_layers': 2}, 24: {u'learning rate': 0.0001, u'dropout_rate': 0.2, u'hidden_dim': 128, u'num_layers': 2}, 25: {u'learning rate': 0.0001, u'dropout_rate': 0.6000000000000001, u'hidden_dim': 320, u'num_layers': 2}, 26: {u'learning rate': 0.01, u'dropout_rate': 0.8, u'hidden_dim': 448, u'num_layers': 3}, 27: {u'learning rate': 0.0001, u'dropout_rate': 0.2, u'hidden_dim': 384, u'num_layers': 1}, 28: {u'learning rate': 0.01, u'dropout_rate': 0.6000000000000001, u'hidden_dim': 320, u'num_layers': 1}, 29: {u'learning rate': 0.1, u'dropout_rate': 0.2, u'hidden_dim': 320, u'num_layers': 2}, 30: {u'learning rate': 0.0001, u'dropout_rate': 0.4, u'hidden_dim': 192, u'num_layers': 3}, 31: {u'learning rate': 0.01, u'dropout_rate': 0.6000000000000001, u'hidden_dim': 448, u'num_layers': 1}, 32: {u'learning rate': 0.01, u'dropout_rate': 0.6000000000000001, u'hidden_dim': 64, u'num_layers': 1}, 33: {u'learning rate': 0.0001, u'dropout_rate': 0.4, u'hidden_dim': 64, u'num_layers': 3}, 34: {u'learning rate': 0.1, u'dropout_rate': 0.2, u'hidden_dim': 64, u'num_layers': 1}, 35: {u'learning rate': 0.001, u'dropout_rate': 0.6000000000000001, u'hidden_dim': 320, u'num_layers': 2}, 36: {u'learning rate': 0.0001, u'dropout_rate': 0.2, u'hidden_dim': 448, u'num_layers': 1}, 37: {u'learning rate': 0.0001, u'dropout_rate': 0.6000000000000001, u'hidden_dim': 320, u'num_layers': 2}, 38: {u'learning rate': 0.0001, u'dropout_rate': 0.6000000000000001, u'hidden_dim': 64, u'num_layers': 2}, 39: {u'learning rate': 0.0001, u'dropout_rate': 0.8, u'hidden_dim': 128, u'num_layers': 3}, 40: {u'learning rate': 0.001, u'dropout_rate': 0.4, u'hidden_dim': 256, u'num_layers': 3}, 41: {u'learning rate': 0.0001, u'dropout_rate': 0.8, u'hidden_dim': 64, u'num_layers': 1}, 42: {u'learning rate': 0.01, u'dropout_rate': 0.8, u'hidden_dim': 128, u'num_layers': 3}, 43: {u'learning rate': 0.0001, u'dropout_rate': 0.8, u'hidden_dim': 64, u'num_layers': 3}, 44: {u'learning rate': 0.01, u'dropout_rate': 0.4, u'hidden_dim': 64, u'num_layers': 3}, 45: {u'learning rate': 0.01, u'dropout_rate': 0.6000000000000001, u'hidden_dim': 448, u'num_layers': 3}, 46: {u'learning rate': 0.0001, u'dropout_rate': 0.6000000000000001, u'hidden_dim': 256, u'num_layers': 1}, 47: {u'learning rate': 0.01, u'dropout_rate': 0.2, u'hidden_dim': 448, u'num_layers': 3}, 48: {u'learning rate': 0.01, u'dropout_rate': 0.2, u'hidden_dim': 320, u'num_layers': 3}, 49: {u'learning rate': 0.01, u'dropout_rate': 0.4, u'hidden_dim': 64, u'num_layers': 1}, 50: {u'learning rate': 0.01, u'dropout_rate': 0.2, u'hidden_dim': 256, u'num_layers': 3}, 51: {u'learning rate': 0.01, u'dropout_rate': 0.2, u'hidden_dim': 384, u'num_layers': 3}, 52: {u'learning rate': 0.01, u'dropout_rate': 0.4, u'hidden_dim': 192, u'num_layers': 1}, 53: {u'learning rate': 0.0001, u'dropout_rate': 0.8, u'hidden_dim': 64, u'num_layers': 3}, 54: {u'learning rate': 0.0001, u'dropout_rate': 0.2, u'hidden_dim': 320, u'num_layers': 3}, 55: {u'learning rate': 0.1, u'dropout_rate': 0.8, u'hidden_dim': 192, u'num_layers': 1}, 56: {u'learning rate': 0.1, u'dropout_rate': 0.2, u'hidden_dim': 192, u'num_layers': 1}, 57: {u'learning rate': 0.0001, u'dropout_rate': 0.2, u'hidden_dim': 64, u'num_layers': 1}, 58: {u'learning rate': 0.1, u'dropout_rate': 0.4, u'hidden_dim': 384, u'num_layers': 2}, 59: {u'learning rate': 0.001, u'dropout_rate': 0.8, u'hidden_dim': 384, u'num_layers': 3}, 60: {u'learning rate': 0.0001, u'dropout_rate': 0.6000000000000001, u'hidden_dim': 64, u'num_layers': 3}, 61: {u'learning rate': 0.01, u'dropout_rate': 0.8, u'hidden_dim': 64, u'num_layers': 1}, 62: {u'learning rate': 0.001, u'dropout_rate': 0.4, u'hidden_dim': 64, u'num_layers': 2}, 63: {u'learning rate': 0.1, u'dropout_rate': 0.8, u'hidden_dim': 256, u'num_layers': 1}, 64: {u'learning rate': 0.0001, u'dropout_rate': 0.2, u'hidden_dim': 256, u'num_layers': 1}, 65: {u'learning rate': 0.1, u'dropout_rate': 0.2, u'hidden_dim': 384, u'num_layers': 3}, 66: {u'learning rate': 0.1, u'dropout_rate': 0.8, u'hidden_dim': 384, u'num_layers': 3}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_steps = 30\n",
    "output_steps = 60\n",
    "input_size = 2\n",
    "output_size = 1\n",
    "\n",
    "train_idx = list(range(3000))\n",
    "valid_idx = list(range(3000,4000))\n",
    "test_idx = list(range(4000,5000))\n",
    "for i in tqdm(range(31, max_evals)):\n",
    "    \"\"\"\n",
    "    random_params = {k: random.sample(v, 1)[0] for k, v in param_grid.items()}\n",
    "    learning_rate = random_params[\"learning rate\"]\n",
    "    dropout_rate = random_params[\"dropout_rate\"]\n",
    "    num_layers = random_params[\"num_layers\"]\n",
    "    hidden_dim = random_params[\"hidden_dim\"]\n",
    "    \"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    encoder = Encoder(input_size, hidden_dim, num_layers, dropout_rate)\n",
    "    decoder = Decoder(output_size, hidden_dim, num_layers, dropout_rate)\n",
    "    model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "    model, loss, preds, min_valid_loss = train_model(model, X, Y, \n",
    "                                                     learning_rate, \n",
    "                                                     output_steps = output_steps, \n",
    "                                                     batch_size = 64,\n",
    "                                                     train_idx = train_idx,\n",
    "                                                     valid_idx = valid_idx,\n",
    "                                                     test_idx = test_idx)  \n",
    "    try:\n",
    "        torch.save({\n",
    "                'learning_rate': learning_rate,\n",
    "                'dropout_rate': dropout_rate,\n",
    "                'num_layers':num_layers,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'loss': loss,\n",
    "                'min_valid_loss': min_valid_loss,\n",
    "                'preds':preds,\n",
    "                },\"/home/eliza/mlhc/tune/final/lstms_at/aop-\" + str(i) +\".pt\")\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE for varying forecast horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters selected by random search.\n",
    "learning_rate = 0.01\n",
    "dropout_rate = 0.6\n",
    "num_layers = 1\n",
    "hidden_dim = 128\n",
    "\n",
    "input_steps = 30\n",
    "output_steps = 60\n",
    "input_size = 2\n",
    "output_size = 1\n",
    "\n",
    "\n",
    "learning_rate = best_params[\"learning_rate\"]\n",
    "dropout_rate = best_params[\"dropout_rate\"]\n",
    "num_layers = best_params[\"num_layers\"]\n",
    "hidden_dim = best_params[\"hidden_dim\"]\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "encoder = Encoder(input_size, hidden_dim, num_layers, dropout_rate)\n",
    "decoder = Decoder(output_size, hidden_dim, num_layers, dropout_rate)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "model, loss, preds, min_valid_loss = train_model(model, learning_rate, output_steps, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'learning_rate': learning_rate,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'num_layers':num_layers,\n",
    "            'hidden_dim': hidden_dim,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'loss': loss,\n",
    "            'min_valid_loss': min_valid_loss,\n",
    "            'preds':preds,\n",
    "            },\"/home/rui/KDD/Tune/Horizon/LSTMs/101AOP-\"+ str(output_steps) + \"-\" + str(k) + \".pt\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best I-D-S Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_state(model_name):\n",
    "    model_state = torch.load(os.path.abspath('../tune/horizon/%s/aop_at.pt' % model_name))['model_state_dict']\n",
    "    return model_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters selected by random search.\n",
    "learning_rate = 0.01\n",
    "dropout_rate = 0.6\n",
    "num_layers = 1\n",
    "hidden_dim = 128\n",
    "\n",
    "input_steps = 30\n",
    "output_steps = 60\n",
    "input_size = 2\n",
    "output_size = 1\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "encoder = Encoder(input_size, hidden_dim, num_layers, dropout_rate)\n",
    "decoder = Decoder(output_size, hidden_dim, num_layers, dropout_rate)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "        \n",
    "model.load_state_dict(get_model_state('lstms_at'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case with One Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate rt to at\n",
    "def rt_to_at(rt):\n",
    "    at = rt.reshape(rt.shape[0], int(WINDOW_SIZE/STEP_SIZE), STEP_SIZE, 2).mean(2)\n",
    "    return at\n",
    "random_patient_index = np.random.randint(0, len(listdir(SLICES_DIR)))\n",
    "test_rt_data_file = listdir(SLICES_DIR)[random_patient_index]\n",
    "test_rt_data = torch.load(join(SLICES_DIR, test_rt_data_file))\n",
    "test_at_data = rt_to_at(test_rt_data)\n",
    "plt.figure(figsize=(15,2.5))\n",
    "random_data_index = np.random.randint(0, len(test_rt_data))\n",
    "rt_data_sample = test_rt_data[random_data_index][:, 0]\n",
    "at_data_sample = test_at_data[random_data_index][:, 0].view(-1, 1).repeat(1,  STEP_SIZE).reshape(WINDOW_SIZE)\n",
    "plt.plot(rt_data_sample, label=\"RT\", linewidth=0.3)\n",
    "plt.plot(at_data_sample, label=\"AT\", linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENT_ID = '1715047' # 171504 data points, 17150 seconds, 43.06667 minutes\n",
    "x = torch.load(os.path.abspath('../data/data/patient/%s_at_x' % PATIENT_ID))\n",
    "y = torch.load(os.path.abspath('../data/data/patient/%s_at_y' % PATIENT_ID))\n",
    "sample_size, pred_length, feature_count = x.shape\n",
    "\n",
    "def scale_with_avg_std(data_x, data_y, avg, std, c_avg, c_std):\n",
    "    data_x[:,:,0] = (data_x[:,:,0] - avg)/std\n",
    "    data_x[:,:,1] = (data_x[:,:,1] - c_avg)/c_std\n",
    "    data_y = (data_y-avg)/std\n",
    "    return data_x, data_y\n",
    "x, y = scale_with_avg_std(x, y, avg, std, c_avg, c_std)\n",
    "\n",
    "def scale_with_avg_std(data_x, data_y, avg, std, c_avg, c_std):\n",
    "    data_x[:,:,0] = (data_x[:,:,0] - avg)/std\n",
    "    data_x[:,:,1] = (data_x[:,:,1] - c_avg)/c_std\n",
    "    data_y = (data_y-avg)/std\n",
    "    return data_x, data_y\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "test_rmse, test_set = [], Dataset(x, y, np.array(range(sample_size)), output_steps)\n",
    "test_generator = data.DataLoader(test_set, batch_size = 64, shuffle = False)\n",
    "t_rmse, test_predictions = run_epoch_eval(model, test_generator, criterion, return_pred = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_scaled = torch.from_numpy(test_predictions)\n",
    "true_predictions_scaled = y.squeeze(-1)\n",
    "\n",
    "# unscale actual and aop_input \n",
    "# after * std + avg = original\n",
    "def unscale_data(scaled_data, avg, std):\n",
    "    data = scaled_data * std + avg\n",
    "    return data\n",
    "test_predictions = unscale_data(test_predictions_scaled, avg, std)\n",
    "true_predictions = unscale_data(true_predictions_scaled, avg, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aop_input = torch.load(os.path.abspath('../data/data/patient/%s_at_x' % PATIENT_ID))[..., 0]\n",
    "actual = torch.load(os.path.abspath('../data/data/patient/%s_at_y' % PATIENT_ID)).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'patient_rmse': t_rmse,\n",
    "            'patient_preds': test_predictions,\n",
    "            'aop_input': aop_input,\n",
    "            'actual': actual,\n",
    "            },\"/home/eliza/mlhc/tune/horizon/lstm_at_%s.pt\" % PATIENT_ID)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_at_patient = torch.load(\"/home/eliza/mlhc/tune/horizon/lstm_at_%s.pt\" % PATIENT_ID)\n",
    "aop_input = transformer_at_patient['aop_input']\n",
    "test_predictions = transformer_at_patient['patient_preds']\n",
    "print(transformer_at_patient['patient_rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "plt.plot(aop_input[:24 * 360 + 1], label = \"Ground Truth\", linewidth = 0.1, color = \"blue\")\n",
    "plt.plot(test_predictions[:24 * 360 + 1], label = \"LSTMs(AT)\",linewidth = 0.1, color = \"orange\")\n",
    "\n",
    "\n",
    "plt.xlabel('Time (hours)')\n",
    "locs = range(0, 24 * 360 + 1, 360)\n",
    "labels = [str(label) for label in range(0, 25, 1)]\n",
    "plt.xticks(locs, labels)\n",
    "\n",
    "plt.savefig(join(IMG_DIR, \"lstm_%s_long.png\" % PATIENT_ID), dpi = 400, bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBPLOT_COUNT = 2\n",
    "DATA_COUNT = 100\n",
    "OUTPUT_STEP = 30\n",
    "SUBPLOT_HEIGHT = 3\n",
    "fig, axes = plt.subplots(SUBPLOT_COUNT, 1, sharex=True, sharey=True, figsize=(15, SUBPLOT_HEIGHT * SUBPLOT_COUNT))\n",
    "\n",
    "for i in range(SUBPLOT_COUNT):\n",
    "    plot_aop_input = aop_input[i * DATA_COUNT : (i + 1) * DATA_COUNT].reshape(OUTPUT_STEP * DATA_COUNT)\n",
    "    plot_test_predictions = test_predictions[i * DATA_COUNT : (i + 1) * DATA_COUNT].reshape(OUTPUT_STEP * DATA_COUNT)\n",
    "    axes[i].plot(plot_aop_input, label = \"Ground Truth\", linewidth = 1, color = \"blue\")\n",
    "    axes[i].plot(plot_test_predictions, label = \"LSTMs(AT)\",linewidth = 1, color = \"orange\")\n",
    "    axes[i].grid(axis='y', alpha=0.5)\n",
    "    \n",
    "# plt.savefig(join(IMG_DIR, \"lstm_%s.png\" % PATIENT_ID), dpi = 400, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
